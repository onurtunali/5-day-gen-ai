{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "load_dotenv()  # API key is stored in .env file\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "data = pd.read_csv(\"../data/amazon_products.csv\", usecols=[\"asin\", \"title\", \"category_id\"])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.groupby(\"category_id\").sample(n=5)\n",
    "valid = data[~data.asin.isin(train.asin.values)].groupby(\"category_id\").sample(n=1)\n",
    "train.category_id.nunique() == valid.category_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "from tqdm.rich import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "@retry.Retry(timeout=300.0)\n",
    "def embed_fn(text: str) -> list[float]:\n",
    "    # You will be performing classification, so set task_type accordingly.\n",
    "    response = genai.embed_content(model=\"models/text-embedding-004\", content=text, task_type=\"classification\")\n",
    "\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"title\"].progress_apply(embed_fn)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_embeddings(train)\n",
    "valid = create_embeddings(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {id_: label for label, id_ in enumerate(train.category_id.unique())}\n",
    "label2id = {label: id_ for label, id_ in enumerate(train.category_id.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"label\"] = train.category_id.map(id2label)\n",
    "valid[\"label\"] = valid.category_id.map(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input([input_size], name=\"embedding_inputs\"),\n",
    "            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive the embedding size from observing the data. The embedding size can also be specified\n",
    "# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\n",
    "embedding_size = len(train[\"Embeddings\"].iloc[0])\n",
    "\n",
    "classifier = build_classification_model(embedding_size, len(train[\"label\"].unique()))\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = train[\"label\"]\n",
    "x_train = np.stack(train[\"Embeddings\"])\n",
    "y_val = valid[\"label\"]\n",
    "x_val = np.stack(valid[\"Embeddings\"])\n",
    "\n",
    "# Specify that it's OK to stop early if accuracy stabilises.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "history = classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5-day-gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

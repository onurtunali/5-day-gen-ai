{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "load_dotenv()  # API key is stored in .env file\n",
    "\n",
    "SEED = int(os.getenv(\"SEED\", \"1337\"))\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# We are using amazon products dataset instead of newsgroup\n",
    "data = pd.read_csv(\"../data/amazon_products.csv\", usecols=[\"asin\", \"title\", \"category_id\"]).rename(\n",
    "    columns={\"title\": \"Text\"}\n",
    ")\n",
    "categories = pd.read_csv(\"../data/amazon_categories.csv\").rename(columns={\"id\": \"category_id\"})\n",
    "data = data.merge(categories, on=\"category_id\", how=\"left\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.groupby(\"category_id\").sample(n=2, random_state=SEED).reset_index(drop=True)\n",
    "valid = (\n",
    "    data[~data.asin.isin(train.asin.values)]\n",
    "    .groupby(\"category_id\")\n",
    "    .sample(n=1, random_state=SEED)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "assert train.category_id.nunique() == valid.category_id.nunique()\n",
    "\n",
    "id2label = {id_: label for label, id_ in enumerate(sorted(train.category_id.unique()))}\n",
    "label2id = {label: id_ for label, id_ in enumerate(sorted(train.category_id.unique()))}\n",
    "\n",
    "train[\"Label\"] = train.category_id.map(id2label)\n",
    "valid[\"Label\"] = valid.category_id.map(id2label)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "sample_row = train.loc[idx, \"Text\"]\n",
    "label = train.loc[idx, \"Label\"]\n",
    "category_name = train.loc[idx, \"category_name\"]\n",
    "\n",
    "sample_row, label, category_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = genai.GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "response = baseline_model.generate_content(sample_row)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Using amazom product taxonomy information, which category this product belongs to:\"\n",
    "\n",
    "response = baseline_model.generate_content([prompt, sample_row])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "# You can use a system instruction to do more direct prompting, and get a\n",
    "# more succinct answer.\n",
    "\n",
    "system_instruct = \"\"\"\n",
    "You are a classification service. You will be passed input that represents\n",
    "an amazon product title and you must respond with the amazon taxonomy (deep category name) leaf.\n",
    "\"\"\"\n",
    "\n",
    "instructed_model = genai.GenerativeModel(\"gemini-1.5-flash-001\", system_instruction=system_instruct)\n",
    "\n",
    "retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "\n",
    "# If you want to evaluate your own technique, replace this function with your\n",
    "# model, prompt and other code and return the predicted answer.\n",
    "def predict_label(post: str) -> str:\n",
    "    response = instructed_model.generate_content(post, request_options=retry_policy)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        # Clean up the response.\n",
    "        return response.text.strip()\n",
    "\n",
    "\n",
    "prediction = predict_label(sample_row)\n",
    "\n",
    "print(prediction)\n",
    "print()\n",
    "print(\"Correct!\" if prediction == category_name else \"Incorrect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.rich import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Make predictions using the sampled data.\n",
    "valid[\"Prediction\"] = valid[\"Text\"].progress_apply(predict_label)\n",
    "\n",
    "# And calculate the accuracy.\n",
    "accuracy = (valid[\"category_name\"] == valid[\"Prediction\"]).sum() / len(valid)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[valid.category_name == valid.Prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "model_id = f\"amazon-product-classification-{random.randint(10000,9999999)}\"\n",
    "tuning_op = genai.create_tuned_model(\n",
    "    \"models/gemini-1.5-flash-001-tuning\",\n",
    "    training_data=train,\n",
    "    input_key=\"Text\",\n",
    "    output_key=\"category_name\",\n",
    "    id=model_id,\n",
    "    display_name=\"Amazon Product Classification\",\n",
    "    batch_size=16,\n",
    "    epoch_count=2,\n",
    ")\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "while (tuned_model := genai.get_tuned_model(f\"tunedModels/{model_id}\")).state.name != \"ACTIVE\":\n",
    "    print(tuned_model.state)\n",
    "    time.sleep(60)\n",
    "\n",
    "print(f\"Done! The model name is {tuned_model.state.name}\")\n",
    "snapshots = pd.DataFrame(tuned_model.tuning_task.snapshots)\n",
    "sns.lineplot(data=snapshots, x=\"step\", y=\"mean_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model = genai.GenerativeModel(f\"tunedModels/{model_id}\")\n",
    "\n",
    "idx = 10\n",
    "valid_sample = valid.loc[idx, \"Text\"]\n",
    "label = valid.loc[idx, \"Label\"]\n",
    "category_name = valid.loc[idx, \"category_name\"]\n",
    "\n",
    "print(valid_sample)\n",
    "print(category_name)\n",
    "\n",
    "response = your_model.generate_content(valid_sample)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text: str) -> str:\n",
    "    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n",
    "    response = your_model.generate_content(text, request_options=retry_policy)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        return rc.content.parts[0].text\n",
    "\n",
    "\n",
    "valid[\"Prediction_fine_tuned\"] = valid[\"Text\"].progress_apply(classify_text)\n",
    "\n",
    "accuracy = (valid[\"category_name\"] == valid[\"Prediction_fine_tuned\"]).sum() / len(valid)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the *input* cost of the baseline model with system instructions.\n",
    "sysint_tokens = instructed_model.count_tokens(sample_row).total_tokens\n",
    "print(f\"System instructed baseline model: {sysint_tokens} (input)\")\n",
    "\n",
    "# Calculate the input cost of the tuned model.\n",
    "tuned_tokens = your_model.count_tokens(sample_row).total_tokens\n",
    "print(f\"Tuned model: {tuned_tokens} (input)\")\n",
    "\n",
    "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
    "print(f\"Token savings: {savings:.2%}\")  # Note that this is only n=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_token_output = response.usage_metadata.candidates_token_count\n",
    "print(\"Baseline (verbose) output tokens:\", baseline_token_output)\n",
    "\n",
    "tuned_model_output = your_model.generate_content(sample_row)\n",
    "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
    "print(\"Tuned output tokens:\", tuned_tokens_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5-day-gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
